{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Basic Concepts\n",
    "- Predict Types\n",
    "- Model Save & Load\n",
    "- Hyperparameter Optimization\n",
    "- Evaluation Methods\n",
    "- Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width :98% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### HTML display 조정\n",
    "display(HTML(\"<style>.container {width :98% !important;}</style>\"))\n",
    "\n",
    "### Warning 제거\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_squared_log_error, r2_score, explained_variance_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score, log_loss, matthews_corrcoef, cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix, classification_report, precision_recall_curve, roc_curve, roc_auc_score, auc\n",
    "from sklearn.metrics import PrecisionRecallDisplay, RocCurveDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary: Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df = pd.read_csv('./data/titanic_train.csv')\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터를 재로딩 하고, feature데이터 셋과 Label 데이터 셋 추출. \n",
    "y_titanic_df = titanic_df['Survived']\n",
    "x_titanic_df = titanic_df.drop('Survived', axis=1)\n",
    "\n",
    "# fill NA\n",
    "x_titanic_df['Age'].fillna(x_titanic_df['Age'].mean(), inplace=True)\n",
    "x_titanic_df['Cabin'].fillna('N', inplace=True)\n",
    "x_titanic_df['Embarked'].fillna('N', inplace=True)\n",
    "x_titanic_df['Fare'].fillna(0, inplace=True)\n",
    "\n",
    "# 머신러닝 알고리즘에 불필요한 피처 제거\n",
    "x_titanic_df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "\n",
    "# Label encoding\n",
    "x_titanic_df['Cabin'] = x_titanic_df['Cabin'].str[:1]\n",
    "for feature in ['Cabin', 'Sex', 'Embarked']:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(x_titanic_df[feature])\n",
    "    x_titanic_df[feature] = le.transform(x_titanic_df[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_titanic_df, y_titanic_df, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 정확도: 0.7877\n",
      "RandomForestClassifier 정확도:0.8547\n",
      "LogisticRegression 정확도: 0.8659\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "rf_clf = RandomForestClassifier(random_state=11)\n",
    "lr_clf = LogisticRegression(solver='liblinear') # 작은 데이터에서 유리한 solver\n",
    "\n",
    "# DecisionTreeClassifier 학습/예측/평가\n",
    "dt_clf.fit(x_train, y_train)\n",
    "dt_pred = dt_clf.predict(x_test)\n",
    "print('DecisionTreeClassifier 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
    "\n",
    "# RandomForestClassifier 학습/예측/평가\n",
    "rf_clf.fit(x_train, y_train)\n",
    "rf_pred = rf_clf.predict(x_test)\n",
    "print('RandomForestClassifier 정확도:{0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
    "\n",
    "# LogisticRegression 학습/예측/평가\n",
    "lr_clf.fit(x_train, y_train)\n",
    "lr_pred = lr_clf.predict(x_test)\n",
    "print('LogisticRegression 정확도: {0:.4f}'.format(accuracy_score(y_test, lr_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass: Iris dataset\n",
    "- Multiclass 적용 알고리즘\n",
    "    - OvR (One-versus-the-rest): 분류 시 가장 높은 결정 점수를 클래스로 결정\n",
    "    - OvO (One-versus-one): 각 조합마다 이진 분류기 훈련\n",
    "        - Logistic Regression, SVClassifier 등 이진 분류만 가능한 알고리즘\n",
    "        - Train set의 크기에 영향을 많이 받는 알고리즘 (SVClassifier)\n",
    "- Multi-label & Multi-output Classification\n",
    "    - Multi-label: 하나의 케이스가 여러 label을 갖는 경우\n",
    "    - Multi-label에서, label이 Multiclass의 성질을 갖는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_label = iris.target\n",
    "\n",
    "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, iris_y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=11)\n",
    "dt_clf.fit(x_train, y_train) # scale 적용하지 않음\n",
    "\n",
    "### Logistic Regression - Softmax\n",
    "softmax_reg = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", C=10, random_state=42)\n",
    "softmax_reg.fit(x_train_scaled, y_train)\n",
    "\n",
    "### Linear SVC\n",
    "svm_clf = LinearSVC()\n",
    "svm_clf.fit(x_train_scaled, y_train)\n",
    "\n",
    "### Bagging\n",
    "bagging_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier())\n",
    "bagging_clf.fit(x_train_scaled, y_train)\n",
    "\n",
    "### Adaboost\n",
    "ada_clf = AdaBoostClassifier(base_estimator=None)\n",
    "ada_clf.fit(x_train_scaled, y_train)\n",
    "\n",
    "### Random Forest\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "rnd_clf.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree 예측 정확도: 0.9333\n",
      "Logistic 예측 정확도: 0.9333\n",
      "SVC 예측 정확도: 0.7667\n",
      "Bagging 예측 정확도: 0.9333\n",
      "AdaBoost 예측 정확도: 0.9333\n",
      "RandomForest 예측 정확도: 0.9333\n"
     ]
    }
   ],
   "source": [
    "### Test predict\n",
    "dt_iris_pred = dt_clf.predict(x_test)\n",
    "lr_iris_pred = softmax_reg.predict(x_test_scaled)\n",
    "svc_iris_pred = svm_clf.predict(x_test_scaled)\n",
    "bagging_iris_pred = bagging_clf.predict(x_test_scaled)\n",
    "ada_iris_pred = ada_clf.predict(x_test_scaled)\n",
    "rnd_iris_pred = rnd_clf.predict(x_test_scaled)\n",
    "\n",
    "print(f'Tree 예측 정확도: {round(accuracy_score(iris_y_test, dt_iris_pred), 4)}')\n",
    "print(f'Logistic 예측 정확도: {round(accuracy_score(iris_y_test, lr_iris_pred), 4)}')\n",
    "print(f'SVC 예측 정확도: {round(accuracy_score(iris_y_test, svc_iris_pred), 4)}')\n",
    "print(f'Bagging 예측 정확도: {round(accuracy_score(iris_y_test, bagging_iris_pred), 4)}')\n",
    "print(f'AdaBoost 예측 정확도: {round(accuracy_score(iris_y_test, ada_iris_pred), 4)}')\n",
    "print(f'RandomForest 예측 정확도: {round(accuracy_score(iris_y_test, rnd_iris_pred), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree\n",
      "[[ 9  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  2  9]]\n",
      "Logistic\n",
      "[[ 8  1  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1 10]]\n",
      "SVC\n",
      "[[8 1 0]\n",
      " [0 6 4]\n",
      " [0 2 9]]\n",
      "Bagging\n",
      "[[ 9  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  2  9]]\n",
      "AdaBoost\n",
      "[[ 9  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  2  9]]\n",
      "RandomForest\n",
      "[[ 9  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  2  9]]\n"
     ]
    }
   ],
   "source": [
    "### Confusion matrix\n",
    "print(f'Tree\\n{confusion_matrix(iris_y_test, dt_iris_pred)}')\n",
    "print(f'Logistic\\n{confusion_matrix(iris_y_test, lr_iris_pred)}')\n",
    "print(f'SVC\\n{confusion_matrix(iris_y_test, svc_iris_pred)}')\n",
    "\n",
    "print(f'Bagging\\n{confusion_matrix(iris_y_test, bagging_iris_pred)}')\n",
    "print(f'AdaBoost\\n{confusion_matrix(iris_y_test, ada_iris_pred)}')\n",
    "print(f'RandomForest\\n{confusion_matrix(iris_y_test, rnd_iris_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree: [[0. 1. 0.]]\n",
      "Logistic: [[2.94615675e-08 1.03572333e-03 9.98964247e-01]]\n",
      "Bagging: [[0. 0. 1.]]\n",
      "AdaBoost: [[3.18895177e-16 1.25442809e-04 9.99874557e-01]]\n"
     ]
    }
   ],
   "source": [
    "### Class probability\n",
    "# 알고리즘 특성 상 Tree는 1, 0으로 구성되고, SVC는 확률을 제공하지 않음\n",
    "print(f'Tree: {dt_clf.predict_proba([[5, 2, 3, 3]])}')\n",
    "print(f'Logistic: {softmax_reg.predict_proba(scaler.transform(np.array([[5, 2, 3, 3]])))}')\n",
    "\n",
    "print(f'Bagging: {bagging_clf.predict_proba([[5, 2, 3, 3]])}')\n",
    "print(f'AdaBoost: {ada_clf.predict_proba([[5, 2, 3, 3]])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree: [1]\n",
      "Logistic: [2]\n",
      "SVC: [2]\n",
      "Bagging: [2]\n",
      "AdaBoost: [2]\n"
     ]
    }
   ],
   "source": [
    "### New data predict\n",
    "print(f'Tree: {dt_clf.predict([[5, 2, 3, 3]])}')\n",
    "print(f'Logistic: {softmax_reg.predict(scaler.transform(np.array([[5, 2, 3, 3]])))}')\n",
    "print(f'SVC: {svm_clf.predict(scaler.transform(np.array([[5, 2, 3, 3]])))}')\n",
    "\n",
    "print(f'Bagging: {bagging_clf.predict(scaler.transform(np.array([[5, 2, 3, 3]])))}')\n",
    "print(f'AdaBoost: {ada_clf.predict(scaler.transform(np.array([[5, 2, 3, 3]])))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC(gamma='auto', random_state=42))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OvO 또는 OvR 강제\n",
    "svc = SVC(gamma=\"auto\", random_state=42)\n",
    "ovr_clf = OneVsRestClassifier(svc)\n",
    "ovr_clf.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SVC(gamma='auto', random_state=42),\n",
       " SVC(gamma='auto', random_state=42),\n",
       " SVC(gamma='auto', random_state=42)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ovr_clf.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multi-label\n",
    "# 두 가지 label 생성\n",
    "y_train_1 = (y_train <= 1)\n",
    "y_train_2 = (y_train == 1)\n",
    "\n",
    "y_test_1 = (iris_y_test <= 1)\n",
    "y_test_2 = (iris_y_test == 1)\n",
    "\n",
    "y_train_multilabel = np.c_[y_train_1, y_train_2]\n",
    "y_test_multilabel = np.c_[y_test_1, y_test_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(x_train_scaled, y_train_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred = knn_clf.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False],\n",
       "       [False, False],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [False, False]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9097826086956522"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test_multilabel, knn_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multi-output\n",
    "y_train_1 = y_train\n",
    "y_train_2 = (y_train == 1)\n",
    "\n",
    "y_train_multilabel = np.c_[y_train_1, y_train_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_clf.fit(x_train, y_train_multilabel)\n",
    "knn_pred = knn_clf.predict([x_test[2]])\n",
    "knn_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boston dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = pd.read_csv('./data/boston.csv')\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 10)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   longitude           20640 non-null  float64\n",
      " 1   latitude            20640 non-null  float64\n",
      " 2   housing_median_age  20640 non-null  float64\n",
      " 3   total_rooms         20640 non-null  float64\n",
      " 4   total_bedrooms      20433 non-null  float64\n",
      " 5   population          20640 non-null  float64\n",
      " 6   households          20640 non-null  float64\n",
      " 7   median_income       20640 non-null  float64\n",
      " 8   median_house_value  20640 non-null  float64\n",
      " 9   ocean_proximity     20640 non-null  object \n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "boston.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        207\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "ocean_proximity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston.isna().sum() # no NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'MEDV'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2890\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2891\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2892\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MEDV'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-26407879a3df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# seaborn의 regplot을 이용해 산점도와 선형 회귀직선을 함께 시각화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboston\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MEDV'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mboston\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2891\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2892\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2893\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2895\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'MEDV'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(figsize=(12, 8), ncols=4, nrows=3, constrained_layout=True) # 3개의 행과 4개의 열을 가진 subplot\n",
    "features = boston.columns.difference(['MEDV', 'CHAS'])\n",
    "for i, feature in zip(range(12), features):\n",
    "    row = i//4 # 행번호 설정\n",
    "    col = i%4 # 열번호 설정\n",
    "    \n",
    "    # seaborn의 regplot을 이용해 산점도와 선형 회귀직선을 함께 시각화\n",
    "    sns.regplot(x=feature, y=boston['MEDV'], data=boston, ax=axs[row][col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_x = boston[features].values\n",
    "boston_y = boston['MEDV'].values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(boston_x, boston_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('학습데이터세트 PRICE 평균: ', y_train.mean())\n",
    "print('평가데이터세트 PRICE 평균: ', y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Linear Regression\n",
    "linear = LinearRegression()\n",
    "linear.fit(x_train_scaled, y_train)\n",
    "\n",
    "### Ridge\n",
    "ridge = Ridge()\n",
    "ridge.fit(x_train_scaled, y_train)\n",
    "\n",
    "### Lasso\n",
    "lasso = Lasso()\n",
    "lasso.fit(x_train_scaled, y_train)\n",
    "\n",
    "### ElasticNet\n",
    "elastic = ElasticNet()\n",
    "elastic.fit(x_train_scaled, y_train)\n",
    "\n",
    "### Decision Tree\n",
    "dt_reg = DecisionTreeRegressor(random_state=0, max_depth=4)\n",
    "dt_reg.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test predict\n",
    "linear_pred = linear.predict(x_test_scaled)\n",
    "ridge_pred = ridge.predict(x_test_scaled)\n",
    "lasso_pred = ridge.predict(x_test_scaled)\n",
    "elastic_pred = elastic.predict(x_test_scaled)\n",
    "dt_pred = dt_reg.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### R2-score\n",
    "print(f'Linear R2-Score: {round(r2_score(y_test, linear_pred), 4)}')\n",
    "print(f'Ridge R2-Score: {round(r2_score(y_test, ridge_pred), 4)}')\n",
    "print(f'Lasso R2-Score: {round(r2_score(y_test, lasso_pred), 4)}')\n",
    "\n",
    "print(f'ElasticNet R2-Score: {round(r2_score(y_test, elastic_pred), 4)}')\n",
    "print(f'Tree R2-Score: {round(r2_score(y_test, dt_pred), 4)}')\n",
    "print('')\n",
    "\n",
    "### MSE\n",
    "print(f'Linear MSE: {round(mean_squared_error(y_test, linear_pred), 4)}')\n",
    "print(f'Ridge MSE: {round(mean_squared_error(y_test, ridge_pred), 4)}')\n",
    "print(f'Lasso MSE: {round(mean_squared_error(y_test, lasso_pred), 4)}')\n",
    "\n",
    "print(f'ElasticNet MSE: {round(mean_squared_error(y_test, elastic_pred), 4)}')\n",
    "print(f'Tree MSE: {round(mean_squared_error(y_test, dt_pred), 4)}')\n",
    "print('')\n",
    "\n",
    "### MAE\n",
    "print(f'Linear MAE: {round(mean_absolute_error(y_test, linear_pred), 4)}')\n",
    "print(f'Ridge MAE: {round(mean_absolute_error(y_test, ridge_pred), 4)}')\n",
    "print(f'Lasso MAE: {round(mean_absolute_error(y_test, lasso_pred), 4)}')\n",
    "\n",
    "print(f'ElasticNet MAE: {round(mean_absolute_error(y_test, elastic_pred), 4)}')\n",
    "print(f'Tree MAE: {round(mean_absolute_error(y_test, dt_pred), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Linear Regression 절편 값:', linear.intercept_)\n",
    "print('Linear Regression 회귀 계수값:', np.round(linear.coef_, 1))\n",
    "\n",
    "print('Ridge 절편 값:', ridge.intercept_)\n",
    "print('Ridge 회귀 계수값:', np.round(ridge.coef_, 1))\n",
    "\n",
    "print('Lasso 절편 값:', lasso.intercept_)\n",
    "print('Lasso 회귀 계수값:', np.round(lasso.coef_, 1))\n",
    "\n",
    "print('ElasticNet 절편 값:', elastic.intercept_)\n",
    "print('ElasticNet 회귀 계수값:', np.round(elastic.coef_, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### New data predict\n",
    "print(f'Linear Regression: {linear.predict([x_test[0]])}')\n",
    "print(f'Ridge: {ridge.predict([x_test[0]])}')\n",
    "print(f'Lasso: {lasso.predict([x_test[0]])}')\n",
    "print(f'ElasticNet: {elastic.predict([x_test[0]])}')\n",
    "print(f'Tree: {dt_reg.predict([x_test[0]])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model save & load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### model save\n",
    "# joblib.dump(linear, \"my_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model load\n",
    "# my_model_loaded = joblib.load(\"my_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Permutation Importance\n",
    "- 일반적으로 수행되는 중요도 판정 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tree feature importance\n",
    "print(\"Feature importances:{0}\".format(np.round(dt_clf.feature_importances_, 3)))\n",
    "for name, value in zip(iris_df.columns.difference(['label']), dt_clf.feature_importances_):\n",
    "    print('{0} : {1:.3f}'.format(name, value))\n",
    "\n",
    "sns.barplot(x=dt_clf.feature_importances_, y=iris_df.columns.difference(['Class', 'label']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AdaBoost feature importance\n",
    "print(\"Feature importances:{0}\".format(np.round(ada_clf.feature_importances_, 3)))\n",
    "for name, value in zip(iris_df.columns.difference(['label']), ada_clf.feature_importances_):\n",
    "    print('{0} : {1:.3f}'.format(name, value))\n",
    "\n",
    "sns.barplot(x=ada_clf.feature_importances_, y=iris_df.columns.difference(['Class', 'label']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RandomForest feature importance\n",
    "print(\"Feature importances:{0}\".format(np.round(rnd_clf.feature_importances_, 3)))\n",
    "for name, value in zip(iris_df.columns.difference(['label']), rnd_clf.feature_importances_):\n",
    "    print('{0} : {1:.3f}'.format(name, value))\n",
    "\n",
    "sns.barplot(x=rnd_clf.feature_importances_, y=iris_df.columns.difference(['Class', 'label']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Logistic Regression feature importance\n",
    "# coef_의 경우 각 class에 대하여 반환되므로, 기준 변수를 설정해야 함 (Clas==0으로 설정)\n",
    "print(\"Class 0 coef:{0}\".format(np.round(softmax_reg.coef_, 3)[0]))\n",
    "for name, value in zip(iris_df.columns.difference(['label']), softmax_reg.coef_[0]):\n",
    "    print('{0} : {1:.3f}'.format(name, value))\n",
    "\n",
    "sns.barplot(x=abs(softmax_reg.coef_[0]), y=iris_df.columns.difference(['label']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVC feature importance\n",
    "# LinearSVC의 경우에만 사용 가능\n",
    "print(\"Class 0 coef:{0}\".format(np.round(svm_clf.coef_, 3)[0]))\n",
    "for name, value in zip(iris_df.columns.difference(['label']), svm_clf.coef_[0]):\n",
    "    print('{0} : {1:.3f}'.format(name, value))\n",
    "\n",
    "sns.barplot(x=abs(svm_clf.coef_[0]), y=iris_df.columns.difference(['label']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀 계수를 큰 값 순으로 정렬하기 위해 Series로 생성. index가 칼럼명에 유의\n",
    "coeff = pd.Series(data=np.round(linear.coef_, 1), index=features).sort_values(ascending=False)\n",
    "plt.title('Linear Regression Coefficient')\n",
    "sns.barplot(x=coeff.values, y=coeff.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = pd.Series(data=np.round(ridge.coef_, 1), index=features).sort_values(ascending=False)\n",
    "plt.title('Ridge Coefficient')\n",
    "sns.barplot(x=coeff.values, y=coeff.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = pd.Series(data=np.round(lasso.coef_, 1), index=features).sort_values(ascending=False)\n",
    "plt.title('Lasso Coefficient')\n",
    "sns.barplot(x=coeff.values, y=coeff.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = pd.Series(data=np.round(elastic.coef_, 1), index=features).sort_values(ascending=False)\n",
    "plt.title('ElasticNet Coefficient')\n",
    "sns.barplot(x=coeff.values, y=coeff.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Decision Tree: Feature importance\n",
    "feature_series = pd.Series(data=dt_reg.feature_importances_, index=features).sort_values(ascending=False)\n",
    "sns.barplot(x=feature_series, y=feature_series.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Drop Column Importance\n",
    "- 각 독립변수를 하나씩 제거한 모델과 전체 모델의 결과 비교\n",
    "- 자체적인 독립변수 중요도 평가 방법이 존재하지 않는 모델인 경우\n",
    "- 원리 이해와 해석이 상대적으로 쉬운 편\n",
    "- Full model과 각 독립변수가 하나씩 제거된 Reduced model을 모두 학습해야 하므로, 시간이 오래 걸릴 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "- Domain 지식을 이용한 추가/삭제 (현업 의견 필요)\n",
    "- target 변수와의 연관성(유의성) 검정\n",
    "- Auto Selections\n",
    "    - 일변량 통계\n",
    "    - 모델 기반 선택\n",
    "    - 반복적 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Univariate Statistics\n",
    "- 각 특성은 독립적인 것으로 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile, f_classif, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regression\n",
    "select = SelectPercentile(score_func=f_regression, percentile=80) # regression인 경우 f_regression\n",
    "x_train_sel = select.fit_transform(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(x_train_sel.shape) # 80% 이상의 변수가 선택됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = select.get_support()\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_titanic_df, y_titanic_df, test_size=0.2, random_state=11)\n",
    "select = SelectPercentile(score_func=f_classif, percentile=80) # classification인 경우 f_classif\n",
    "x_train_sel = select.fit_transform(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(x_train_sel.shape) # 80% 이상의 변수가 선택됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.loc[:, select.get_support()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Model-based Selection\n",
    "- 특성의 중요도를 이용한 변수 선택\n",
    "- 분석의 목적에 맞게 Classifier/Regressor 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = SelectFromModel(RandomForestClassifier(), threshold=\"median\") # threshold는 숫자 지정도 가능\n",
    "x_train_rf = select.fit_transform(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "print(x_train_rf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.loc[:, select.get_support()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Iterative Selection\n",
    "- 특성을 선택하지 않은 상태에서 종료 조건에 도달할 때까지 추가\n",
    "- 특성을 모두 선택한 상태에서 종료 조건에 도달할 때까지 제거 (RFE)\n",
    "- 회귀분석 변수선택과 유사한 면이 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = RFE(RandomForestClassifier(), n_features_to_select=6)\n",
    "x_train_rfe = select.fit_transform(x_train, y_train)\n",
    "print(x_train_rfe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### predict도 가능\n",
    "select.predict(x_test)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Evaluation\n",
    "- Business Impact를 고려한 지표 선택 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Classification\n",
    "- Multi-Class의 경우 Class 값으로 예측값이 주어지지 않는 경우가 있어, 데이터 변형이 필요할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_titanic_df, y_titanic_df, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "- 전체 데이터에서 정답의 개수. 데이터 구성에 따라 성능이 왜곡될 가능성 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix\n",
    "- Accuray의 한계점 보완"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Multiclass인 경우 사용\n",
    "# 각 클래스와 나머지 클래스 비교 (OvR) 방식\n",
    "multilabel_confusion_matrix(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision & Recall (=Sensitivity, TPR)\n",
    "- Positive 예측에 집중한 지표. Positive 중 실제 Positive 비율 / 실제 Positive 중 예측된 Positive 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Precision\n",
    "precision_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Recall\n",
    "recall_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Precision & Recall, trade-offs\n",
    "# predict_proba()\n",
    "pred_proba = lr_clf.predict_proba(x_test)\n",
    "pred = lr_clf.predict(x_test)\n",
    "print('pred_proba()결과 Shape : {0}'.format(pred_proba.shape))\n",
    "print('pred_proba array에서 앞 3개만 샘플로 추출 \\n:', pred_proba[:3])\n",
    "\n",
    "# 예측 확률 array 와 예측 결과값 array 를 concatenate 하여 예측 확률과 결과값을 한눈에 확인\n",
    "pred_proba_result = np.concatenate([pred_proba, pred.reshape(-1, 1)], axis=1)\n",
    "print('두개의 class 중에서 더 큰 확률을 클래스 값으로 예측 \\n', pred_proba_result[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Binarizer: 확률 값을 label 값으로 변경해 줌. np.where을 대신 써도 무방\n",
    "# threshold 설정값 = 분류 결정 임곗값 \n",
    "custom_threshold = 0.5\n",
    "\n",
    "# predict_proba() 반환값의 두번째 컬럼 , 즉 Positive 클래스 컬럼 하나만 추출하여 Binarizer 적용\n",
    "pred_proba_1 = pred_proba[:, 1].reshape(-1, 1)\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "confusion = confusion_matrix(y_test, custom_predict)\n",
    "accuracy = accuracy_score(y_test, custom_predict)\n",
    "precision = precision_score(y_test, custom_predict)\n",
    "recall = recall_score(y_test, custom_predict)\n",
    "print('오차 행렬\\n', confusion)\n",
    "print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizer의 threshold 설정값을 0.4로 설정\n",
    "custom_threshold = 0.4\n",
    "\n",
    "pred_proba_1 = pred_proba[:,1].reshape(-1, 1)\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_1) \n",
    "custom_predict = binarizer.transform(pred_proba_1)\n",
    "\n",
    "confusion = confusion_matrix(y_test, custom_predict)\n",
    "accuracy = accuracy_score(y_test, custom_predict)\n",
    "precision = precision_score(y_test, custom_predict)\n",
    "recall = recall_score(y_test, custom_predict)\n",
    "print('오차 행렬\\n', confusion)\n",
    "print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_c1 = pred_proba[:, 1].reshape(-1, 1)\n",
    "\n",
    "for custom_threshold in [0.4, 0.45, 0.50, 0.55, 0.60]:\n",
    "    binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) \n",
    "    custom_predict = binarizer.transform(pred_proba_c1)\n",
    "    print('임곗값:', custom_threshold)\n",
    "    \n",
    "    confusion = confusion_matrix(y_test, custom_predict)\n",
    "    accuracy = accuracy_score(y_test, custom_predict)\n",
    "    precision = precision_score(y_test, custom_predict)\n",
    "    recall = recall_score(y_test, custom_predict)\n",
    "    print('오차 행렬\\n', confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}'.format(accuracy, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### precision_recall_curve\n",
    "# 확률 cutoff에 따른 precision-recall의 변화 시각화\n",
    "# cutoff가 높을수록 precision이 커지고  recall은 작아짐\n",
    "# 레이블 값이 1일때의 예측 확률을 추출 \n",
    "pred_proba_class1 = lr_clf.predict_proba(x_test)[:, 1] \n",
    "\n",
    "# 실제값 데이터 셋과 레이블 값이 1일 때의 예측 확률을 precision_recall_curve 인자로 입력 \n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1)\n",
    "print('반환된 분류 결정 임곗값 배열의 Shape:', thresholds.shape)\n",
    "print('반환된 precisions 배열의 Shape:', precisions.shape)\n",
    "print('반환된 recalls 배열의 Shape:', recalls.shape)\n",
    "\n",
    "print(\"thresholds 5 sample:\", thresholds[:5])\n",
    "print(\"precisions 5 sample:\", precisions[:5])\n",
    "print(\"recalls 5 sample:\", recalls[:5])\n",
    "\n",
    "#반환된 임계값 배열 로우가 147건이므로 샘플로 10건만 추출하되, 임곗값을 15 Step으로 추출. \n",
    "thr_index = np.arange(0, thresholds.shape[0], 15)\n",
    "print('샘플 추출을 위한 임계값 배열의 index 10개:', thr_index)\n",
    "print('샘플용 10개의 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "\n",
    "# 15 step 단위로 추출된 임계값에 따른 정밀도와 재현율 값 \n",
    "print('샘플 임계값별 정밀도: ', np.round(precisions[thr_index], 3))\n",
    "print('샘플 임계값별 재현율: ', np.round(recalls[thr_index], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Precision - Recall plot\n",
    "# threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출. \n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, lr_clf.predict_proba(x_test)[:, 1])\n",
    "    \n",
    "# X축을 threshold값으로, Y축은 정밀도, 재현율 값으로 각각 Plot 수행. 정밀도는 점선으로 표시\n",
    "plt.figure(figsize=(8, 6))\n",
    "threshold_boundary = thresholds.shape[0]\n",
    "sns.lineplot(x=thresholds, y=precisions[0:threshold_boundary], linestyle='dashed', label='precision')\n",
    "sns.lineplot(x=thresholds, y=recalls[0:threshold_boundary], label='recall')\n",
    "    \n",
    "# threshold 값 X 축의 Scale을 0.1 단위로 변경\n",
    "start, end = plt.xlim()\n",
    "plt.xticks(np.round(np.arange(start, end, 0.1), 2))\n",
    "    \n",
    "# x축, y축 label과 legend\n",
    "plt.xlabel('Threshold value'); plt.ylabel('Precision and Recall value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = PrecisionRecallDisplay(precision=precisions, recall=recalls)\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification report\n",
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1-Score / Fb-Score\n",
    "- Precision, Recall의 조화평균\n",
    "- beta 값으로 precision과 recall의 가중치를 조정할 수 있음 (값이 클수록 recall의 가중치가 올라감)\n",
    "- Multiclass에서 Score Averaging \n",
    "    - None: 각 클래스 별 점수 산출\n",
    "    - Micro-Averaging (마이크로 평균)\n",
    "        - 각 클래스의 TP, FP, FN을 모두 더해 전체적으로 하나의 큰 confusion matrix를 생성\n",
    "        - Precision과 Recall을 이 confusion matrix에 대해 계산한 후 F1 스코어 계산\n",
    "        - 모든 클래스의 예측과 실제 값들을 하나로 합쳐서 계산하기 때문에, 클래스 간 밸런스가 중요하지 않은 경우에 유용\n",
    "        - 클래스 간 샘플 수 밸런스가 필요 없으며, 모든 클래스를 하나의 큰 클래스로 취급하기 때문에 클래스 빈도에 영향을 덜 받음\n",
    "        - 이진 분류에서와 마찬가지로 모든 예측과 실제값을 묶어서 계산하기 때문에, 데이터의 전체적인 성능을 확인할 수 있음\n",
    "        - 클래스 간 불균형이 심한 경우에는 작은 클래스의 성능이 무시될 수 있으며, 클래스 크기가 다른 경우 각 클래스의 중요도를 반영하지 않음\n",
    "    - Macro-Averaging (매크로 평균)\n",
    "        - 각 클래스 별로 따로 Precision과 Recall을 계산한 후, 모든 클래스의 평균 계산\n",
    "        - 클래스 간 밸런스가 중요한 경우 사용됨\n",
    "        - 각 클래스의 F1 스코어가 동등한 가중치를 갖게 됨\n",
    "        - 각 클래스 별로 독립적으로 평가하므로, 클래스 간 밸런스가 중요한 경우에 적합하며, 모든 클래스의 성능을 동등하게 취급하여 중요한 클래스의 성능도 고려함\n",
    "        - 클래스 간 샘플 수 밸런스가 불균형한 경우, 큰 클래스가 평균에 미치는 영향이 더 크게 나타날 수 있고 클래스 크기에 상관없이 동등한 가중치를 부여하기 때문에 작은 클래스의 성능이 상대적으로 중요한 경우에는 적절하지 않음\n",
    "    - Weighted-Averaging (가중 평균)\n",
    "        - 클래스 별로 Precision과 Recall을 계산한 후, 각 클래스의 샘플 수를 기반으로 가중 평균 계산\n",
    "        - 클래스 간 밸런스가 중요하면서 각 클래스가 다른 샘플 수를 가지는 경우에 사용\n",
    "        - 클래스별로 F1 스코어를 가중하여 전체적인 성능 평가\n",
    "        - 클래스 별로 샘플 수에 따라 가중치를 부여하기 때문에 클래스 간 샘플 수 및 중요도를 모두 고려할 수 있고 클래스 간 밸런스와 각 클래스의 중요도가 동시에 고려되므로 다양한 상황에 적용 가능함\n",
    "        - 클래스 간 샘플 수가 크게 불균형한 경우, 작은 클래스의 성능이 무시될 수 있음. 또한 클래스 크기와 중요도를 고려하면서도, 작은 클래스의 성능을 충분히 평가하는 방법을 선택하는 것이 중요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### binary\n",
    "f1_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### f2-score\n",
    "fbeta_score(y_test, pred, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = lr_clf.predict_proba(x_test)\n",
    "pred_proba_c1 = pred_proba[:, 1].reshape(-1, 1)\n",
    "for custom_threshold in [0.4, 0.45, 0.50, 0.55, 0.60]:\n",
    "    binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1) \n",
    "    custom_predict = binarizer.transform(pred_proba_c1)\n",
    "    print('임곗값:', custom_threshold)\n",
    "\n",
    "    confusion = confusion_matrix(y_test, custom_predict)\n",
    "    accuracy = accuracy_score(y_test, custom_predict)\n",
    "    precision = precision_score(y_test, custom_predict)\n",
    "    recall = recall_score(y_test, custom_predict)\n",
    "    f1 = f1_score(y_test, custom_predict)\n",
    "    \n",
    "    print('오차 행렬\\n', confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}'.format(accuracy, precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### multiclass\n",
    "f1_score(iris_y_test, dt_iris_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specificity \n",
    "- 실제 음성인 데이터 중 음성으로 올바르게 예측한 데이터 비율\n",
    "- Negative에 대한 Recall\n",
    "- 1 - FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score(y_test, lr_pred, pos_label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Predictive Value\n",
    "- 음성으로 예측한 데이터 중 음성으로 올바르게 예측한 데이터 비율\n",
    "- Negative에 대한 Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_score(y_test, lr_pred, pos_label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC & AUC/Gini\n",
    "- 확률 cutoff에 따른 FPR(False Positive Rate) 대비 TPR(True Positive Rate)의 변화와 그 비율을 판단\n",
    "- 분류가 무작위이면 AUC는 0.5에 가까우며, 분류 성능이 좋을수록 1에 가까움\n",
    "- Gini coefficient = 2 * AUC - 1로 계산하고 AUC와 선형 관계 (-1~1 사이 값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 값이 1일때의 예측 확률을 추출 \n",
    "pred_proba_class1 = lr_clf.predict_proba(x_test)[:, 1] \n",
    "\n",
    "fprs, tprs, thresholds = roc_curve(y_test, pred_proba_class1)\n",
    "# 반환된 임곗값 배열에서 샘플로 데이터를 추출하되, 임곗값을 5 Step으로 추출. \n",
    "# thresholds[0]은 max(예측확률)+1로 임의 설정됨. 이를 제외하기 위해 np.arange는 1부터 시작\n",
    "thr_index = np.arange(1, thresholds.shape[0], 5)\n",
    "print('샘플 추출을 위한 임곗값 배열의 index:', thr_index)\n",
    "print('샘플 index로 추출한 임곗값: ', np.round(thresholds[thr_index], 2))\n",
    "\n",
    "# 5 step 단위로 추출된 임계값에 따른 FPR, TPR 값\n",
    "print('샘플 임곗값별 FPR: ', np.round(fprs[thr_index], 3))\n",
    "print('샘플 임곗값별 TPR: ', np.round(tprs[thr_index], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ROC\n",
    "# 임곗값에 따른 FPR, TPR 값을 반환 받음\n",
    "fprs, tprs, thresholds = roc_curve(y_test, lr_clf.predict_proba(x_test)[:, 1])\n",
    "\n",
    "sns.lineplot(x=fprs, y=tprs, ci=False, label='ROC')\n",
    "sns.lineplot(x=[0, 1], y=[0, 1], color='black', linestyle='dashed', label='Random')\n",
    "    \n",
    "# FPR X 축의 Scale을 0.1 단위로 변경, X,Y 축명 설정등   \n",
    "start, end = plt.xlim()\n",
    "plt.xticks(np.round(np.arange(start, end, 0.1),2))\n",
    "plt.xlim(0,1); plt.ylim(0,1)\n",
    "plt.xlabel('FPR( 1 - Specificity )'); plt.ylabel('TPR( Recall )')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, pred_proba_class1) \n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc) # plot_roc_curve(logistic, test_x, test_y)함수가 sklearn 1.2.1부터 대체됨\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = lr_clf.predict_proba(x_test)[:, 1]\n",
    "roc_auc_score(y_test, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(roc_auc_score(y_test, pred_proba) * 2) - 1 # Gini index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Loss\n",
    "- Logistic Loss, Cross-entropy Loss\n",
    "- 이진 분류에서만 사용 가능\n",
    "- 모델이 예측한 확률 분포와 실제 레이블의 확률 분포 간의 차이를 측정함\n",
    "- 양성 예측 확률에 로그를 취하고 부호 반전\n",
    "- 낮을수록 좋은 성능 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gain & Lift\n",
    "- 이익(Gain): 목표 범주에 속하는 개체들이 각 등급에 얼마나 분포하고 있는지 나타냄\n",
    "- 향상도(Lift): 랜덤 모델 대비 얼마나 모델의 성과가 얼마나 있는지 등급별로 파악"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class가 명확하게 정의된 데이터에서만 가능\n",
    "### Gain table generate\n",
    "def get_gain_table(clf, X, y, num_group=10):\n",
    "    res_df = pd.DataFrame()\n",
    "    res_df['response'] = y\n",
    "    class_idx = np.where(clf.classes_==1)[0][0]\n",
    "    \n",
    "    res_df['prob'] = clf.predict_proba(X)[:, class_idx]\n",
    "    res_df = res_df.sort_values('prob', ascending=False).reset_index(drop=True) ## 확률값으로 내림차순\n",
    "    res_df['temp'] = range(len(res_df))\n",
    "\n",
    "    res_df['group'] = pd.qcut(res_df['temp'], num_group, labels=list(range(1, num_group+1))) ## 데이터 num_group 수만큼 분할\n",
    "    res_df = res_df.groupby('group').agg({'response': ['sum', 'count']}).reset_index() ## \n",
    "    res_df.columns = ['group', 'num_of_response', 'num_of_data']\n",
    "    res_df = res_df.sort_values('group')\n",
    "    res_df['individual_gain'] = res_df['num_of_response']/np.sum(y) ## 구간별 gain\n",
    "    res_df['gain'] = res_df['individual_gain'].cumsum() ## gain\n",
    "    \n",
    "    return res_df\n",
    "\n",
    "### Lift table generate\n",
    "def get_lift_table(clf, X, y, num_group=10):\n",
    "    res_df = pd.DataFrame()\n",
    "    res_df['response'] = y\n",
    "    class_idx = np.where(clf.classes_==1)[0][0]\n",
    "    \n",
    "    res_df['prob'] = clf.predict_proba(X)[:, class_idx]\n",
    "    res_df = res_df.sort_values('prob', ascending=False).reset_index(drop=True) ## 확률값으로 내림차순\n",
    "    res_df['temp'] = range(len(res_df))\n",
    "    res_df['group'] = pd.qcut(res_df['temp'], num_group, labels=list(range(1, num_group+1))) ## 데이터 num_group 수만큼 분할\n",
    "    res_df = res_df.groupby('group').agg({'response': ['sum', 'count', 'mean']}).reset_index() ## \n",
    "    res_df.columns = ['group', 'num_of_response', 'num_of_data', 'response_rate']\n",
    "    res_df = res_df.sort_values('group')\n",
    "    \n",
    "    baseline_lift = np.sum(y)/len(y)\n",
    "    res_df['lift'] = res_df['response_rate']/baseline_lift # Lift\n",
    "    \n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_df = get_gain_table(lr_clf, x_test, y_test)\n",
    "gain_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=gain_df['group'], y=gain_df['gain'], marker='o')\n",
    "\n",
    "plt.title('Gain Chart', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift_df = get_lift_table(lr_clf, x_test, y_test)\n",
    "lift_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x=lift_df['group'], y=lift_df['lift'], marker='o')\n",
    "plt.title('Lift Chart', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MCC (Matthews Correlation Coefficient)\n",
    "- 불균형한 데이터의 모델 성능을 평가하기 좋음\n",
    "- -1~1사이의 값을 가지며, 0은 랜덤 예측, 값이 클수록 성능이 좋다고 평가함\n",
    "- F1-score와 달리 양성과 음성을 대칭으로 취급함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matthews_corrcoef(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QWK (Quadratic Weighted Kappa)\n",
    "- 다중 클래스 분류에서 클래스 간 순서가 있을 때 사용\n",
    "- 각 행 데이터의 예측이 어느 클래스인지 확인\n",
    "- 0은 랜덤 예측, 1이면 완벽한 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_kappa_score(y_test, lr_pred, weights='quadratic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(boston_x, boston_y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "\n",
    "pred = linear.predict(x_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE\n",
    "- Mean Absolute Error\n",
    "- 에러 크기 그대로 반영하나 예측 에러의 방향은 알 수 없음 (과소 예측/과대 예측 판단 불가)\n",
    "- MAE를 최소화하는 예측값은 중앙값\n",
    "- 에러에 따른 손실이 선형적으로 올라가야 하는 경우나 이상치가 많을 때 사용 (MSE보다 이상치 영향 적음)\n",
    "- 변수 scale에 의존적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAPE\n",
    "- Mean Absolute Percentage Error\n",
    "- 오차가 예측값에서 차지하는 정도 (MAE를 비율로 변환한 것)\n",
    "- 비율 변수이므로, 모델 간 성능 비교가 용이하나 비율 해석이 의미가 있는 경우에만 사용 가능\n",
    "- 데이터에 0이 있을 경우 사용 불가하고, 실제 정답이 0에 가까운 매우 작은 값일 경우 값이 매우 커질 수 있음\n",
    "- 주로 시계열 모형에서 사용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(y_test, y_pred):\n",
    "    return np.mean(np.abs((y_test - y_pred)/y_test)) * 100\n",
    "    \n",
    "MAPE(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSE & RMSE\n",
    "- Mean Squared Error\n",
    "- 에러의 면적합\n",
    "- 직관적인 지표이지만  scale에 의존적\n",
    "- (MSE의 경우) 예측 변수와 단위가 다름\n",
    "- (RMSE의 경우) MLE method 결과와 RMSE 최소화 결과가 같아지는 등 통계학적인 의미가 있음\n",
    "- 1 미만 에러는 더 작아지고, 그 이상의 에러는 더 커짐\n",
    "- 에러의 방향을 알 수 없으며 이상치 영향 받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### squared option으로 조정\n",
    "mean_squared_error(y_test, pred, squared=False) # RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R-square\n",
    "- 데이터에 대한 모델의 설명 정도. 0~1로 나타내며 높을 수록 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MSLE\n",
    "- Mean Squared Log Error\n",
    "- MSE에 log 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_squared_log_error(y_test, pred)\n",
    "# msle는 positive 변수일때만 사용 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSLE\n",
    "- 실제값과 예측값에 각각 log 취한 후 그 차이의 제곱평균제곱근으로 계산\n",
    "- RMSE를 최소화하면 RMSLE도 최소화됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSLE(y, pred):\n",
    "    return np.sqrt(np.mean((np.log1p(y) - np.log1p(pred))**2))\n",
    "\n",
    "RMSLE(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "- 데이터 분할의 무작위성 제거\n",
    "- 데이터의 효율적 사용\n",
    "- 연산 비용이 늘어나는 단점이 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (1) K-fold data\n",
    "- K-fold의 결과를 활용한 CV\n",
    "- Regression, Classification 모두 사용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regression\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "# KFold 교차 검증 수행\n",
    "scores = list()\n",
    "for iter_count, (train_index, test_index) in enumerate(kfold.split(boston_x)):\n",
    "    # x_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
    "    x_train, x_test = boston_x[train_index], boston_x[test_index]\n",
    "    y_train, y_test = boston_y[train_index], boston_y[test_index]\n",
    "        \n",
    "    # Classifier 학습, 예측, 정확도 계산 \n",
    "    linear.fit(x_train, y_train) \n",
    "    rmse = mean_squared_error(y_test, linear.predict(x_test), squared=False)\n",
    "    scores.append(rmse)\n",
    "    print(\"교차 검증 {0} RMSE: {1:.4f}\".format(iter_count, rmse))     \n",
    "    \n",
    "# 5개 fold에서의 평균 정확도 계산. \n",
    "mean_score = np.mean(scores)\n",
    "print(\"평균 RMSE: {0:.4f}\".format(mean_score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Classification\n",
    "scores = list()\n",
    "for iter_count, (train_index, test_index) in enumerate(kfold.split(x_titanic_df)):\n",
    "    # x_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
    "    x_train, x_test = x_titanic_df.values[train_index], x_titanic_df.values[test_index]\n",
    "    y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        \n",
    "    # Classifier 학습, 예측, 정확도 계산 \n",
    "    dt_clf.fit(x_train, y_train) \n",
    "    accuracy = accuracy_score(y_test, dt_clf.predict(x_test))\n",
    "    scores.append(accuracy)\n",
    "    print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))     \n",
    "    \n",
    "# 5개 fold에서의 평균 정확도 계산. \n",
    "mean_score = np.mean(scores)\n",
    "print(\"평균 정확도: {0:.4f}\".format(mean_score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stratified K-Fold\n",
    "# Classification 문제에만 사용가능\n",
    "s_kf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# KFold 교차 검증 수행\n",
    "scores = list()\n",
    "for iter_count, (train_index, test_index) in enumerate(s_kf.split(x_titanic_df, y_titanic_df)):\n",
    "    # x_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
    "    x_train, x_test = x_titanic_df.values[train_index], x_titanic_df.values[test_index]\n",
    "    y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        \n",
    "    # Classifier 학습, 예측, 정확도 계산 \n",
    "    dt_clf.fit(x_train, y_train) \n",
    "    accuracy = accuracy_score(y_test, dt_clf.predict(x_test))\n",
    "    scores.append(accuracy)\n",
    "    print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))     \n",
    "    \n",
    "# 5개 fold에서의 평균 정확도 계산. \n",
    "mean_score = np.mean(scores)\n",
    "print(\"평균 정확도: {0:.4f}\".format(mean_score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Group K-Fold\n",
    "g_kf = GroupKFold(n_splits=5)\n",
    "\n",
    "# KFold 교차 검증 수행\n",
    "scores = list()\n",
    "for iter_count, (train_index, test_index) in enumerate(g_kf.split(x_titanic_df, y_titanic_df, groups=x_titanic_df['Cabin'])):\n",
    "    # x_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
    "    x_train, x_test = x_titanic_df.values[train_index], x_titanic_df.values[test_index]\n",
    "    y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        \n",
    "    # Classifier 학습, 예측, 정확도 계산 \n",
    "    dt_clf.fit(x_train, y_train) \n",
    "    accuracy = accuracy_score(y_test, dt_clf.predict(x_test))\n",
    "    scores.append(accuracy)\n",
    "    print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))     \n",
    "    \n",
    "# 5개 fold에서의 평균 정확도 계산. \n",
    "mean_score = np.mean(scores)\n",
    "print(\"평균 정확도: {0:.4f}\".format(mean_score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Shuffle split\n",
    "sfl = ShuffleSplit(test_size=0.2, n_splits=6)\n",
    "\n",
    "scores = list()\n",
    "for iter_count, (train_index, test_index) in enumerate(sfl.split(x_titanic_df, y_titanic_df)):\n",
    "    # x_titanic_df 데이터에서 교차 검증별로 학습과 검증 데이터를 가리키는 index 생성\n",
    "    x_train, x_test = x_titanic_df.values[train_index], x_titanic_df.values[test_index]\n",
    "    y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]\n",
    "        \n",
    "    # Classifier 학습, 예측, 정확도 계산 \n",
    "    dt_clf.fit(x_train, y_train) \n",
    "    accuracy = accuracy_score(y_test, dt_clf.predict(x_test))\n",
    "    scores.append(accuracy)\n",
    "    print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))     \n",
    "    \n",
    "# 5개 fold에서의 평균 정확도 계산. \n",
    "mean_score = np.mean(scores)\n",
    "print(\"평균 정확도: {0:.4f}\".format(mean_score)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) CV Function\n",
    "- cv 변수에 숫자 말고도 분할 클래스를 입력할 수 있음\n",
    "- scoring 변수로 평가 지표 변경 가능\n",
    "    - Classification: accuracy, roc_auc, recall_macro, average_precision, f1, f1_macro(micro/weighted) 등\n",
    "    - Regressiom: r2, neg_mean_squared_error, neg_mean_absolute_error 등\n",
    "- Functions\n",
    "    - cross_val_score: CV로 score 계산\n",
    "    - cross_val_predict: CV로 전체 데이터 예측결과 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### iris dataset\n",
    "# CV로 모델 선정하기\n",
    "dtree_clf_5 = DecisionTreeClassifier(max_depth=5, random_state=100, criterion=\"entropy\") # entropy를 분류기준으로 함\n",
    "dtree_clf_3 = DecisionTreeClassifier(max_depth=3, random_state=100, criterion=\"entropy\")\n",
    "dtree_clf_1 = DecisionTreeClassifier(max_depth=1, random_state=100, criterion=\"entropy\")\n",
    "\n",
    "scores = cross_val_score(dtree_clf_5, iris_data, iris_label, scoring='accuracy', cv=10) # dataset 10개로 분할\n",
    "print('교차검증 정확도: ', np.round(scores, 3))\n",
    "print('평균 검증 정확도: ', np.round(np.mean(scores), 4))\n",
    "\n",
    "scores = cross_val_score(dtree_clf_3, iris_data, iris_label, scoring='accuracy', cv=10)\n",
    "print('교차검증 정확도: ', np.round(scores, 3))\n",
    "print('평균 검증 정확도: ', np.round(np.mean(scores), 4))\n",
    "\n",
    "scores = cross_val_score(dtree_clf_1, iris_data, iris_label, scoring='accuracy', cv=10)\n",
    "print('교차검증 정확도: ', np.round(scores, 3))\n",
    "print('평균 검증 정확도: ', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(dtree_clf_1, iris_data, iris_label, scoring='accuracy', cv=s_kf) # stratified kfold 결과를 input으로 함\n",
    "print('교차검증 정확도: ', np.round(scores, 3))\n",
    "print('평균 검증 정확도: ', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(dtree_clf_1, iris_data, iris_label, scoring='accuracy', cv=g_kf, groups=iris_data[:, 0]) # group kfold 결과를 input으로 함\n",
    "print('교차검증 정확도: ', np.round(scores, 3))\n",
    "print('평균 검증 정확도: ', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(dtree_clf_1, iris_data, iris_label, scoring='accuracy', cv=sfl) # shuffle split 결과를 input으로 함\n",
    "print('교차검증 정확도: ', np.round(scores, 3))\n",
    "print('평균 검증 정확도: ', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOOCV\n",
    "# Leave-One-Out Cross Validation\n",
    "# Fold 하나에 sample 하나인 K-Fold를 입력한 것과 동일\n",
    "scores = cross_val_score(dtree_clf_1, iris_data, iris_label, scoring='accuracy', cv=LeaveOneOut())\n",
    "print('교차검증 정확도: ', np.round(scores, 3))\n",
    "print('평균 검증 정확도: ', np.round(np.mean(scores), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### titanic dataset\n",
    "scores = cross_val_score(dt_clf, x_titanic_df, y_titanic_df, cv=5)\n",
    "for iter_count, accuracy in enumerate(scores):\n",
    "    print(\"교차 검증 {0} 정확도: {1:.4f}\".format(iter_count, accuracy))\n",
    "    \n",
    "print(\"평균 정확도: {0:.4f}\".format(np.mean(scores))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_predict = cross_val_predict(dt_clf, x_titanic_df, y_titanic_df, cv=3)\n",
    "cross_predict[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### boston dataset\n",
    "neg_mse_scores = cross_val_score(linear, boston_x, boston_y, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "rmse_scores  = np.sqrt(-1 * neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "# cross_val_score(scoring=\"neg_mean_squared_error\")로 반환된 값은 모두 음수 \n",
    "print('5 folds 의 개별 Negative MSE scores:', np.round(neg_mse_scores, 2))\n",
    "print('5 folds 의 개별 RMSE scores:', np.round(rmse_scores, 2))\n",
    "print('5 folds 의 평균 RMSE: {0:.3f}'.format(avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_predict = cross_val_predict(linear, boston_x, boston_y, cv=3)\n",
    "cross_predict[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Grid Search\n",
    "- 모든 가능한 조합을 수행\n",
    "- Cross validation 사용\n",
    "- 적절한 파라미터 선택과, 적절한 grid 범위를 설정하는 것이 중요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [2, 3, 5, 10], 'min_samples_split': [2, 3, 5], 'min_samples_leaf': [1, 5, 8]} # parameter grid를 list로 여러 개 입력할 수 있음 -> parameter에 따라 특정 paremeter를 사용하지 않는 경우\n",
    "\n",
    "grid_dclf = GridSearchCV(DecisionTreeClassifier(), param_grid=parameters, scoring='accuracy', cv=3)\n",
    "grid_dclf.fit(x_train, y_train)\n",
    "\n",
    "print('GridSearchCV 최적 하이퍼 파라미터:', grid_dclf.best_params_)\n",
    "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dclf.best_score_))\n",
    "best_dclf = grid_dclf.best_estimator_\n",
    "\n",
    "# GridSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. \n",
    "dpredictions = best_dclf.predict(x_test)\n",
    "accuracy = accuracy_score(iris_y_test, dpredictions)\n",
    "print('테스트 세트에서의 DecisionTreeClassifier 정확도 : {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV 결과 추출하여 DataFrame으로 변환\n",
    "scores_df = pd.DataFrame(grid_dclf.cv_results_)\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nested Cross-Validation\n",
    "# Grid Search로 모델을 만들고, CV로 테스트\n",
    "scores = cross_val_score(GridSearchCV(DecisionTreeClassifier(), param_grid=parameters, cv=5), iris_data, iris_label, cv=s_kf)\n",
    "print(scores)\n",
    "print(\"평균 정확도: {0:.4f}\".format(np.mean(scores))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Randomized Search\n",
    "- 특정 범위에서 파라미터를 랜덤으로 선택\n",
    "- 조합이 매우 많거나, 연속형 값을 조정할 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.fixes import loguniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {'max_depth': [2, 3, 5, 10], 'min_samples_split': [1, 2, 3, 5], 'min_samples_leaf': [1, 5, 8]}\n",
    "rand_dclf = RandomizedSearchCV(DecisionTreeClassifier(), param_distributions=param_distribs, n_iter=5, cv=5, scoring='accuracy')\n",
    "rand_dclf.fit(x_train, y_train)\n",
    "\n",
    "print('RandomizedSearch 최적 하이퍼 파라미터:', rand_dclf.best_params_)\n",
    "print('RandomizedSearch 최고 정확도: {0:.4f}'.format(rand_dclf.best_score_))\n",
    "best_dclf = rand_dclf.best_estimator_\n",
    "\n",
    "# RandomizedSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. \n",
    "dpredictions = best_dclf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, dpredictions)\n",
    "print('테스트 세트에서의 DecisionTreeClassifier 정확도 : {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {'kernel': ['rbf'], 'C': loguniform(0.001, 100)}\n",
    "rand_dclf = RandomizedSearchCV(SVC(), param_distributions=param_distribs, n_iter=5, cv=5, scoring='accuracy')\n",
    "rand_dclf.fit(x_train, y_train)\n",
    "\n",
    "print('RandomizedSearch 최적 하이퍼 파라미터:', rand_dclf.best_params_)\n",
    "print('RandomizedSearch 최고 정확도: {0:.4f}'.format(rand_dclf.best_score_))\n",
    "best_dclf = rand_dclf.best_estimator_\n",
    "\n",
    "# RandomizedSearchCV의 최적 하이퍼 파라미터로 학습된 Estimator로 예측 및 평가 수행. \n",
    "dpredictions = best_dclf.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, dpredictions)\n",
    "print('테스트 세트에서의 SVC 정확도 : {0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install hyperopt\n",
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -10 ~ 10까지 1간격을 가지는 입력 변수 x와 -15 ~ 15까지 1간격으로 입력 변수 y 설정.\n",
    "search_space = {'x': hp.quniform('x', -10, 10, 1), 'y': hp.quniform('y', -15, 15, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목적 함수 생성. 변숫값과 변수 검색 공간을 가지는 딕셔너리를 인자로 받고, 특정 값을 반환\n",
    "def objective_func(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    retval = x**2 - 20*y\n",
    "    \n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 결과값을 저장한 Trials 객체값 생성.\n",
    "trial_val = Trials()\n",
    "\n",
    "# 목적 함수의 최솟값을 반환하는 최적 입력 변숫값을 5번의 입력값 시도(max_evals=5)로 찾아냄.\n",
    "best_01 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=5, trials=trial_val, rstate=np.random.RandomState(0))\n",
    "print('best:', best_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_val = Trials()\n",
    "\n",
    "# max_evals를 20회로 늘려서 재테스트\n",
    "best_02 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=20, trials=trial_val, rstate=np.random.RandomState(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmin()에 인자로 들어가는 Trials 객체의 result 속성에 파이썬 리스트로 목적 함수 반환값들이 저장됨\n",
    "# 리스트 내부의 개별 원소는 {'loss':함수 반환값, 'status':반환 상태값} 와 같은 딕셔너리임. \n",
    "print(trial_val.results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trials 객체의 vals 속성에 {'입력변수명':개별 수행 시마다 입력된 값 리스트} 형태로 저장됨.\n",
    "print(trial_val.vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results에서 loss 키값에 해당하는 밸류들을 추출하여 list로 생성. \n",
    "losses = [loss_dict['loss'] for loss_dict in trial_val.results]\n",
    "\n",
    "# DataFrame으로 생성.\n",
    "result_df = pd.DataFrame({'x': trial_val.vals['x'], 'y': trial_val.vals['y'], 'losses': losses})\n",
    "result_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
